{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csc_matrix\n",
    "from scipy.sparse.linalg import eigs\n",
    "\n",
    "edges_file = open('wisconsin_edges.csv', \"r\")\n",
    "nodes_file = open('wisconsin_nodes.csv', \"r\")\n",
    "\n",
    "# create a dictionary where nodes_dict[i] = name of wikipedia page\n",
    "nodes_dict = {}\n",
    "for line in nodes_file:\n",
    "    nodes_dict[int(line.split(',',1)[0].strip())] = line.split(',',1)[1].strip()\n",
    "\n",
    "node_count = len(nodes_dict)\n",
    "\n",
    "# create adjacency matrix\n",
    "A = np.zeros((node_count, node_count))\n",
    "for line in edges_file:\n",
    "    from_node = int(line.split(',')[0].strip())\n",
    "    to_node = int(line.split(',')[1].strip())\n",
    "    A[to_node, from_node] = 1.0\n",
    "\n",
    "## Add code below to (1) prevent traps and (2) find the most important pages     \n",
    "# Hint -- instead of computing the entire eigen-decomposition of a matrix X using\n",
    "# s, E = np.linalg.eig(A)\n",
    "# you can compute just the first eigenvector with:\n",
    "# s, E = eigs(csc_matrix(A), k = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new Array to hold the normalized matrix\n",
    "Anew = np.zeros((node_count, node_count))\n",
    "\n",
    "# remove traps by adding 0.001\n",
    "for i in range(A.shape[0]):\n",
    "    for j in range(A.shape[1]):\n",
    "        A[i, j] = A[i, j] + 0.001\n",
    "        \n",
    "# normalize\n",
    "for k in range(A.shape[1]):\n",
    "    norm = np.sum(A[:,k])\n",
    "    Anew[:,k] = (A[:,k])/norm\n",
    "\n",
    "# compute Eigenvectors                   \n",
    "s, E = eigs(csc_matrix(Anew), k = 1)           \n",
    "E = np.abs(E)\n",
    "E = E.flatten()\n",
    "\n",
    "# sort\n",
    "E_sort = np.argsort(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2041 4298 3874 ... 1345 2312 5089]\n"
     ]
    }
   ],
   "source": [
    "# print sort, take last and third last elements and find their names\n",
    "print(E_sort)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5089 has page title \"Wisconsin\"\n"
     ]
    }
   ],
   "source": [
    "print(\"5089 has page title \\\"Wisconsin\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1345 has page title \"Madison, Wisconsin\"\n"
     ]
    }
   ],
   "source": [
    "print(\"1345 has page title \\\"Madison, Wisconsin\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
